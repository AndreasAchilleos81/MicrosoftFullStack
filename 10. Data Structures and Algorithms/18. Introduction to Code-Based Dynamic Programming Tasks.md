# Dynamic Programming in Back-End Systems

## Introduction

Efficient back-end systems rely on smart techniques to handle growing demands, optimize performance, and prevent overload. **Dynamic programming enhances system efficiency** by storing and reusing important data, reducing redundant computations.

In this guide, we'll identify practical coding scenarios for dynamic programming in back-end systems, focusing on three key areas:

1. API Rate Limiting
2. Cache Optimization
3. Scheduling Algorithms

---

## 1. API Rate Limiting

### What Is API Rate Limiting?

API rate limiting controls how many API requests a user can make within a certain time period. By storing information about each request, the system can quickly check if a user has reached their limit without recalculating each time.

### Benefits

- Ensures **fair usage** among all users
- Prevents **abuse** and spam
- Protects **system resources** from being overwhelmed
- Maintains **consistent performance**

### How It Works

When a user sends a request, the system checks a counter associated with their API key or IP address. This counter tracks the number of requests made within the current time window. If the user exceeds the limit, the server denies further requests and responds with a **429 Too Many Requests** error, often including information about when the limit will reset.

### C# Implementation: Token Bucket Algorithm

```csharp
public class RateLimiter
{
    private Dictionary<string, UserRateLimit> userLimits;
    private readonly int maxRequests;
    private readonly TimeSpan timeWindow;

    public RateLimiter(int maxRequests, TimeSpan timeWindow)
    {
        this.maxRequests = maxRequests;
        this.timeWindow = timeWindow;
        this.userLimits = new Dictionary<string, UserRateLimit>();
    }

    public RateLimitResult CheckRateLimit(string userId)
    {
        // Get or create user rate limit entry
        if (!userLimits.ContainsKey(userId))
        {
            userLimits[userId] = new UserRateLimit
            {
                RequestCount = 0,
                WindowStart = DateTime.UtcNow
            };
        }

        var userLimit = userLimits[userId];
        var now = DateTime.UtcNow;

        // Check if time window has expired
        if (now - userLimit.WindowStart >= timeWindow)
        {
            // Reset counter for new window
            userLimit.RequestCount = 0;
            userLimit.WindowStart = now;
        }

        // Check if user has exceeded limit
        if (userLimit.RequestCount >= maxRequests)
        {
            var resetTime = userLimit.WindowStart.Add(timeWindow);
            return new RateLimitResult
            {
                IsAllowed = false,
                Message = $"Rate limit exceeded. Try again after {resetTime:HH:mm:ss}",
                ResetTime = resetTime,
                RemainingRequests = 0
            };
        }

        // Increment counter and allow request
        userLimit.RequestCount++;
        return new RateLimitResult
        {
            IsAllowed = true,
            RemainingRequests = maxRequests - userLimit.RequestCount,
            ResetTime = userLimit.WindowStart.Add(timeWindow)
        };
    }
}

public class UserRateLimit
{
    public int RequestCount { get; set; }
    public DateTime WindowStart { get; set; }
}

public class RateLimitResult
{
    public bool IsAllowed { get; set; }
    public string Message { get; set; }
    public DateTime ResetTime { get; set; }
    public int RemainingRequests { get; set; }
}
```

### Usage Example

```csharp
class Program
{
    static void Main(string[] args)
    {
        // Allow 100 requests per minute
        var rateLimiter = new RateLimiter(maxRequests: 100, timeWindow: TimeSpan.FromMinutes(1));

        string userId = "user123";

        // Simulate API requests
        for (int i = 1; i <= 105; i++)
        {
            var result = rateLimiter.CheckRateLimit(userId);

            if (result.IsAllowed)
            {
                Console.WriteLine($"Request {i}: Allowed. Remaining: {result.RemainingRequests}");
            }
            else
            {
                Console.WriteLine($"Request {i}: {result.Message}");
            }
        }
    }
}
```

**Output:**
```
Request 1: Allowed. Remaining: 99
Request 2: Allowed. Remaining: 98
...
Request 100: Allowed. Remaining: 0
Request 101: Rate limit exceeded. Try again after 14:35:22
Request 102: Rate limit exceeded. Try again after 14:35:22
...
```

---

## 2. Cache Optimization

### What Is Cache Optimization?

Cache optimization is the process of improving system efficiency by storing frequently accessed data in a cache for faster retrieval. It applies approaches like **memoization** and **web page caching** to store and reuse the results of expensive operations.

### Benefits

- Reduces **redundant computations**
- Improves **response times** dramatically
- Reduces **server load** and database queries
- Enhances **scalability** during peak traffic
- Improves **user experience**

### How It Works

Instead of querying the database each time a user searches for popular products, the results are stored in a cache (such as in-memory storage like Redis). When another user searches for the same product, the cached results are retrieved instantly, bypassing the need for a database query.

### C# Implementation: In-Memory Cache with Expiration

```csharp
using System.Collections.Concurrent;

public class CacheService<TKey, TValue>
{
    private ConcurrentDictionary<TKey, CacheEntry<TValue>> cache;
    private readonly TimeSpan defaultExpiration;

    public CacheService(TimeSpan defaultExpiration)
    {
        this.cache = new ConcurrentDictionary<TKey, CacheEntry<TValue>>();
        this.defaultExpiration = defaultExpiration;
    }

    public bool TryGet(TKey key, out TValue value)
    {
        if (cache.TryGetValue(key, out var entry))
        {
            // Check if entry has expired
            if (DateTime.UtcNow < entry.ExpirationTime)
            {
                value = entry.Value;
                return true;
            }
            else
            {
                // Remove expired entry
                cache.TryRemove(key, out _);
            }
        }

        value = default;
        return false;
    }

    public void Set(TKey key, TValue value, TimeSpan? expiration = null)
    {
        var expirationTime = DateTime.UtcNow.Add(expiration ?? defaultExpiration);
        var entry = new CacheEntry<TValue>
        {
            Value = value,
            ExpirationTime = expirationTime
        };

        cache[key] = entry;
    }

    public void Remove(TKey key)
    {
        cache.TryRemove(key, out _);
    }

    public void Clear()
    {
        cache.Clear();
    }

    public int Count => cache.Count;
}

public class CacheEntry<TValue>
{
    public TValue Value { get; set; }
    public DateTime ExpirationTime { get; set; }
}
```

### Product Search Example with Cache

```csharp
public class Product
{
    public int Id { get; set; }
    public string Name { get; set; }
    public decimal Price { get; set; }
}

public class ProductService
{
    private CacheService<string, List<Product>> cache;
    private Random random = new Random(); // Simulating database

    public ProductService()
    {
        // Cache results for 5 minutes
        cache = new CacheService<string, List<Product>>(TimeSpan.FromMinutes(5));
    }

    public List<Product> SearchProducts(string query)
    {
        Console.WriteLine($"Searching for: {query}");

        // Try to get from cache first
        if (cache.TryGet(query, out var cachedResults))
        {
            Console.WriteLine("✓ Retrieved from cache (instant!)");
            return cachedResults;
        }

        // Cache miss - query the database
        Console.WriteLine("✗ Cache miss - querying database (slow)...");
        System.Threading.Thread.Sleep(1000); // Simulate slow database query

        var results = QueryDatabase(query);

        // Store in cache for future requests
        cache.Set(query, results);

        return results;
    }

    private List<Product> QueryDatabase(string query)
    {
        // Simulate database query
        return new List<Product>
        {
            new Product { Id = 1, Name = $"{query} - Model A", Price = 99.99m },
            new Product { Id = 2, Name = $"{query} - Model B", Price = 149.99m },
            new Product { Id = 3, Name = $"{query} - Model C", Price = 199.99m }
        };
    }
}
```

### Usage Example

```csharp
class Program
{
    static void Main(string[] args)
    {
        var productService = new ProductService();

        // First search - cache miss (slow)
        Console.WriteLine("=== First Search ===");
        var results1 = productService.SearchProducts("laptop");
        Console.WriteLine($"Found {results1.Count} products\n");

        // Second search for same query - cache hit (fast)
        Console.WriteLine("=== Second Search (same query) ===");
        var results2 = productService.SearchProducts("laptop");
        Console.WriteLine($"Found {results2.Count} products\n");

        // Different search - cache miss
        Console.WriteLine("=== Third Search (different query) ===");
        var results3 = productService.SearchProducts("phone");
        Console.WriteLine($"Found {results3.Count} products");
    }
}
```

**Output:**
```
=== First Search ===
Searching for: laptop
✗ Cache miss - querying database (slow)...
Found 3 products

=== Second Search (same query) ===
Searching for: laptop
✓ Retrieved from cache (instant!)
Found 3 products

=== Third Search (different query) ===
Searching for: phone
✗ Cache miss - querying database (slow)...
Found 3 products
```

### Advanced: LRU Cache Implementation

```csharp
public class LRUCache<TKey, TValue>
{
    private readonly int capacity;
    private readonly Dictionary<TKey, LinkedListNode<CacheItem<TKey, TValue>>> cacheMap;
    private readonly LinkedList<CacheItem<TKey, TValue>> lruList;

    public LRUCache(int capacity)
    {
        this.capacity = capacity;
        this.cacheMap = new Dictionary<TKey, LinkedListNode<CacheItem<TKey, TValue>>>();
        this.lruList = new LinkedList<CacheItem<TKey, TValue>>();
    }

    public bool TryGet(TKey key, out TValue value)
    {
        if (cacheMap.TryGetValue(key, out var node))
        {
            // Move to front (most recently used)
            lruList.Remove(node);
            lruList.AddFirst(node);
            value = node.Value.Value;
            return true;
        }

        value = default;
        return false;
    }

    public void Set(TKey key, TValue value)
    {
        if (cacheMap.TryGetValue(key, out var existingNode))
        {
            // Update existing entry
            lruList.Remove(existingNode);
            existingNode.Value.Value = value;
            lruList.AddFirst(existingNode);
        }
        else
        {
            // Check capacity
            if (cacheMap.Count >= capacity)
            {
                // Remove least recently used item
                var lruNode = lruList.Last;
                cacheMap.Remove(lruNode.Value.Key);
                lruList.RemoveLast();
            }

            // Add new entry
            var cacheItem = new CacheItem<TKey, TValue> { Key = key, Value = value };
            var newNode = new LinkedListNode<CacheItem<TKey, TValue>>(cacheItem);
            lruList.AddFirst(newNode);
            cacheMap[key] = newNode;
        }
    }
}

public class CacheItem<TKey, TValue>
{
    public TKey Key { get; set; }
    public TValue Value { get; set; }
}
```

---

## 3. Scheduling Algorithms

### What Are Scheduling Algorithms?

Scheduling algorithms determine the order or allocation of tasks or processes to resources (such as CPU and memory) in a way that optimizes specific objectives like:

- Minimizing wait time
- Maximizing throughput
- Meeting deadlines
- Balancing workloads

These algorithms store data like task queues, resource states, and priorities to make informed decisions. By reusing historical and intermediate data, they adapt dynamically, reduce redundancy, and balance workloads efficiently.

### Example: Email Server Processing

An email server processing large volumes of emails uses a scheduling algorithm to organize emails into a queue based on factors like:

- **Priority** (urgent vs. regular)
- **Size** (small vs. large attachments)
- **Delivery deadlines**

The algorithm continuously monitors server resources (bandwidth, CPU usage, memory) to decide which emails to process first.

### C# Implementation: Priority-Based Task Scheduler

```csharp
public enum TaskPriority
{
    Low = 1,
    Normal = 2,
    High = 3,
    Urgent = 4
}

public class ScheduledTask
{
    public string Id { get; set; }
    public string Name { get; set; }
    public TaskPriority Priority { get; set; }
    public int Size { get; set; } // MB
    public DateTime Deadline { get; set; }
    public DateTime CreatedAt { get; set; }

    public double UrgencyScore
    {
        get
        {
            // Calculate urgency based on priority, deadline, and size
            double priorityWeight = (int)Priority * 10;
            double timeWeight = (Deadline - DateTime.UtcNow).TotalMinutes;
            double sizeWeight = 1.0 / Size; // Smaller tasks get higher score

            return priorityWeight + (100 / Math.Max(timeWeight, 1)) + sizeWeight;
        }
    }
}

public class TaskScheduler
{
    private List<ScheduledTask> taskQueue;
    private Dictionary<string, TaskStats> taskHistory;
    private ResourceMonitor resources;

    public TaskScheduler()
    {
        taskQueue = new List<ScheduledTask>();
        taskHistory = new Dictionary<string, TaskStats>();
        resources = new ResourceMonitor();
    }

    public void AddTask(ScheduledTask task)
    {
        taskQueue.Add(task);
        Console.WriteLine($"Added task: {task.Name} (Priority: {task.Priority})");
    }

    public List<ScheduledTask> GetOptimizedSchedule()
    {
        // Sort by urgency score (dynamic programming approach)
        var optimizedSchedule = taskQueue
            .OrderByDescending(t => t.UrgencyScore)
            .ThenBy(t => t.Deadline)
            .ToList();

        return optimizedSchedule;
    }

    public void ProcessTasks()
    {
        var schedule = GetOptimizedSchedule();

        Console.WriteLine("\n=== Processing Tasks ===");
        foreach (var task in schedule)
        {
            if (resources.CanHandleTask(task))
            {
                ProcessTask(task);
                resources.AllocateResources(task);
            }
            else
            {
                Console.WriteLine($"⏸ Task {task.Name} postponed (insufficient resources)");
            }
        }
    }

    private void ProcessTask(ScheduledTask task)
    {
        Console.WriteLine($"✓ Processing: {task.Name}");
        Console.WriteLine($"  Priority: {task.Priority}, Size: {task.Size}MB");
        Console.WriteLine($"  Urgency Score: {task.UrgencyScore:F2}");

        // Store task history for future optimization
        taskHistory[task.Id] = new TaskStats
        {
            ProcessedAt = DateTime.UtcNow,
            Priority = task.Priority,
            ProcessingTime = task.Size * 10 // Simulate processing time
        };

        taskQueue.Remove(task);
    }
}

public class ResourceMonitor
{
    public int AvailableCPU { get; set; } = 100; // Percentage
    public int AvailableMemory { get; set; } = 8000; // MB
    public int AvailableBandwidth { get; set; } = 1000; // Mbps

    public bool CanHandleTask(ScheduledTask task)
    {
        // Simple check - in real system, this would be more sophisticated
        return AvailableMemory > task.Size * 10 && AvailableCPU > 20;
    }

    public void AllocateResources(ScheduledTask task)
    {
        AvailableMemory -= task.Size * 10;
        AvailableCPU -= 15;
    }
}

public class TaskStats
{
    public DateTime ProcessedAt { get; set; }
    public TaskPriority Priority { get; set; }
    public int ProcessingTime { get; set; }
}
```

### Email Server Example

```csharp
public class EmailTask : ScheduledTask
{
    public string From { get; set; }
    public string To { get; set; }
    public bool HasAttachment { get; set; }
}

class Program
{
    static void Main(string[] args)
    {
        var scheduler = new TaskScheduler();

        // Add various email tasks
        scheduler.AddTask(new EmailTask
        {
            Id = "1",
            Name = "Newsletter",
            Priority = TaskPriority.Low,
            Size = 5,
            Deadline = DateTime.UtcNow.AddHours(24),
            CreatedAt = DateTime.UtcNow
        });

        scheduler.AddTask(new EmailTask
        {
            Id = "2",
            Name = "Password Reset",
            Priority = TaskPriority.Urgent,
            Size = 1,
            Deadline = DateTime.UtcNow.AddMinutes(5),
            CreatedAt = DateTime.UtcNow
        });

        scheduler.AddTask(new EmailTask
        {
            Id = "3",
            Name = "Monthly Report",
            Priority = TaskPriority.Normal,
            Size = 50,
            Deadline = DateTime.UtcNow.AddHours(2),
            CreatedAt = DateTime.UtcNow
        });

        scheduler.AddTask(new EmailTask
        {
            Id = "4",
            Name = "Security Alert",
            Priority = TaskPriority.High,
            Size = 2,
            Deadline = DateTime.UtcNow.AddMinutes(10),
            CreatedAt = DateTime.UtcNow
        });

        // Process tasks using optimized schedule
        scheduler.ProcessTasks();
    }
}
```

**Output:**
```
Added task: Newsletter (Priority: Low)
Added task: Password Reset (Priority: Urgent)
Added task: Monthly Report (Priority: Normal)
Added task: Security Alert (Priority: High)

=== Processing Tasks ===
✓ Processing: Password Reset
  Priority: Urgent, Size: 1MB
  Urgency Score: 1240.00
✓ Processing: Security Alert
  Priority: High, Size: 2MB
  Urgency Score: 130.50
✓ Processing: Monthly Report
  Priority: Normal, Size: 50MB
  Urgency Score: 25.02
✓ Processing: Newsletter
  Priority: Low, Size: 5MB
  Urgency Score: 10.20
```

---

## Key Takeaways

Dynamic programming techniques help back-end systems be **smarter and more efficient** by:

1. **Storing and reusing information** to avoid redundant computations
2. **Making informed decisions** based on historical data
3. **Adapting dynamically** to changing conditions
4. **Handling tasks quickly and reliably** even during high traffic

### Summary of Techniques

| Technique                 | Purpose                        | Key Benefit                         |
| ------------------------- | ------------------------------ | ----------------------------------- |
| **Rate Limiting**         | Control API request frequency  | Prevents abuse, ensures fair usage  |
| **Cache Optimization**    | Store frequently accessed data | Dramatically faster response times  |
| **Scheduling Algorithms** | Optimize task processing order | Meets deadlines, balances workloads |

Each technique leverages the core principle of dynamic programming: **store intermediate results and reuse them** to make systems more efficient, scalable, and reliable.