# Distributed Caching Overview

## Introduction

Web applications will encounter significant challenges during peak traffic, often resulting in slow page loads and frustrated customers. To prevent this, backend developers will leverage a highly scalable solution like distributed caching to help ensure a seamless user experience.

## What is Distributed Caching?

Distributed caching stores frequently accessed data across multiple servers, unlike traditional caching, which is limited to a single server. Distributed caching spreads the cache workload across a cluster of servers. This approach:

- Reduces data access times
- Prevents bottlenecks
- Ensures the system can handle high traffic by distributing the load efficiently
- Allows each server to manage a smaller portion of data

### C# Example: Basic Cache Interface

```csharp
using System;
using System.Threading.Tasks;

public interface IDistributedCache
{
    Task<string> GetAsync(string key);
    Task SetAsync(string key, string value, TimeSpan expiration);
    Task RemoveAsync(string key);
}
```

## Key Elements of Distributed Caching

### 1. Scalability

Distributed caching ensures scalability by:
- Reducing the load on the database
- Distributing data requests across multiple cache nodes
- Working alongside load balancers to evenly distribute incoming traffic across servers

### C# Example: Using Redis with IDistributedCache

```csharp
using Microsoft.Extensions.Caching.Distributed;
using System;
using System.Text;
using System.Text.Json;
using System.Threading.Tasks;

public class ProductService
{
    private readonly IDistributedCache _cache;
    private readonly IProductRepository _repository;

    public ProductService(IDistributedCache cache, IProductRepository repository)
    {
        _cache = cache;
        _repository = repository;
    }

    public async Task<Product> GetProductAsync(int productId)
    {
        string cacheKey = $"product:{productId}";
        
        // Try to get from cache first
        var cachedData = await _cache.GetStringAsync(cacheKey);
        
        if (!string.IsNullOrEmpty(cachedData))
        {
            // Cache hit - return cached data
            return JsonSerializer.Deserialize<Product>(cachedData);
        }
        
        // Cache miss - fetch from database
        var product = await _repository.GetByIdAsync(productId);
        
        if (product != null)
        {
            // Store in cache for future requests
            var serializedProduct = JsonSerializer.Serialize(product);
            var options = new DistributedCacheEntryOptions
            {
                AbsoluteExpirationRelativeToNow = TimeSpan.FromMinutes(10)
            };
            
            await _cache.SetStringAsync(cacheKey, serializedProduct, options);
        }
        
        return product;
    }
}
```

### 2. Load Balancers

Load balancers are tools that distribute incoming network traffic across multiple servers in a cluster. This ensures no single server is overloaded, improving the overall availability and reliability of the application.

**Example Scenario:** During a flash sale with thousands of users shopping simultaneously on an online store, distributed caching offloads the database by quickly providing cached data, while load balancers ensure traffic is evenly spread across the servers.

### C# Example: Configuration for Redis with Multiple Nodes

```csharp
using Microsoft.Extensions.DependencyInjection;
using StackExchange.Redis;

public class Startup
{
    public void ConfigureServices(IServiceCollection services)
    {
        // Configure Redis with multiple endpoints for distributed caching
        var redisConfiguration = ConfigurationOptions.Parse("server1:6379,server2:6379,server3:6379");
        redisConfiguration.AbortOnConnectFail = false;
        
        services.AddStackExchangeRedisCache(options =>
        {
            options.ConfigurationOptions = redisConfiguration;
            options.InstanceName = "MyApp_";
        });
    }
}
```

### 3. Consistency Across Servers

Consistency ensures that data updates are synchronized across all servers. For instance, when users update their profile picture, distributed caching ensures every server instantly reflects that change.

**Common Tools:** Redis and Memcached are commonly used to maintain consistency.

### C# Example: Invalidating Cache on Update

```csharp
public class UserProfileService
{
    private readonly IDistributedCache _cache;
    private readonly IUserRepository _repository;

    public UserProfileService(IDistributedCache cache, IUserRepository repository)
    {
        _cache = cache;
        _repository = repository;
    }

    public async Task UpdateProfilePictureAsync(int userId, string newPictureUrl)
    {
        // Update in database
        await _repository.UpdateProfilePictureAsync(userId, newPictureUrl);
        
        // Invalidate cache to ensure consistency
        string cacheKey = $"user:profile:{userId}";
        await _cache.RemoveAsync(cacheKey);
        
        // Optionally, update cache immediately with new data
        var updatedUser = await _repository.GetByIdAsync(userId);
        var serializedUser = JsonSerializer.Serialize(updatedUser);
        var options = new DistributedCacheEntryOptions
        {
            AbsoluteExpirationRelativeToNow = TimeSpan.FromHours(1)
        };
        
        await _cache.SetStringAsync(cacheKey, serializedUser, options);
    }
}
```

## Use Cases

Distributed caching is essential for modern architectures:

### 1. Microservices Architecture

In microservices, applications are divided into smaller, independent components, and caching helps these components share data quickly without overloading a single database.

### 2. Cloud-Based Systems

In cloud-based systems, which are hosted across multiple servers, distributed caching ensures fast and reliable access to data.

### C# Example: Caching User Credentials for Authentication

```csharp
using Microsoft.Extensions.Caching.Distributed;
using System;
using System.Security.Cryptography;
using System.Text;
using System.Threading.Tasks;

public class AuthenticationService
{
    private readonly IDistributedCache _cache;
    private readonly IUserRepository _userRepository;

    public AuthenticationService(IDistributedCache cache, IUserRepository userRepository)
    {
        _cache = cache;
        _userRepository = userRepository;
    }

    public async Task<bool> ValidateCredentialsAsync(string username, string password)
    {
        string cacheKey = $"auth:{username}";
        
        // Check cache for user credentials hash
        var cachedHash = await _cache.GetStringAsync(cacheKey);
        
        if (!string.IsNullOrEmpty(cachedHash))
        {
            // Validate against cached hash
            return cachedHash == HashPassword(password);
        }
        
        // Cache miss - fetch from database
        var user = await _userRepository.GetByUsernameAsync(username);
        
        if (user != null && user.PasswordHash == HashPassword(password))
        {
            // Cache the password hash for faster future authentication
            var options = new DistributedCacheEntryOptions
            {
                AbsoluteExpirationRelativeToNow = TimeSpan.FromMinutes(30)
            };
            
            await _cache.SetStringAsync(cacheKey, user.PasswordHash, options);
            return true;
        }
        
        return false;
    }

    private string HashPassword(string password)
    {
        using (var sha256 = SHA256.Create())
        {
            var hashedBytes = sha256.ComputeHash(Encoding.UTF8.GetBytes(password));
            return Convert.ToBase64String(hashedBytes);
        }
    }
}
```

### C# Example: Complete Microservices Caching Setup

```csharp
using Microsoft.AspNetCore.Builder;
using Microsoft.Extensions.DependencyInjection;
using StackExchange.Redis;

public class Program
{
    public static void Main(string[] args)
    {
        var builder = WebApplication.CreateBuilder(args);

        // Add distributed caching with Redis
        builder.Services.AddStackExchangeRedisCache(options =>
        {
            options.Configuration = builder.Configuration.GetConnectionString("Redis");
            options.InstanceName = "ShoppingApp_";
        });

        // Register services
        builder.Services.AddScoped<IProductRepository, ProductRepository>();
        builder.Services.AddScoped<ProductService>();
        builder.Services.AddScoped<IUserRepository, UserRepository>();
        builder.Services.AddScoped<AuthenticationService>();

        builder.Services.AddControllers();

        var app = builder.Build();

        app.MapControllers();
        app.Run();
    }
}

// Example API Controller using cached service
[ApiController]
[Route("api/[controller]")]
public class ProductsController : ControllerBase
{
    private readonly ProductService _productService;

    public ProductsController(ProductService productService)
    {
        _productService = productService;
    }

    [HttpGet("{id}")]
    public async Task<IActionResult> GetProduct(int id)
    {
        var product = await _productService.GetProductAsync(id);
        
        if (product == null)
            return NotFound();
            
        return Ok(product);
    }
}
```

## Conclusion

Distributed caching transforms how applications handle growth and user demands, ensuring speed and consistency at scale. By leveraging tools like Redis and implementing proper caching strategies, developers can create highly performant and scalable web applications that provide seamless user experiences even under heavy load.